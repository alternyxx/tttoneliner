use std::fs::File;
use std::io::BufReader;
use neuralnyx::{
    NeuralNet,
    Structure,
    Layer,
    TrainingOptions,
};
use neuralnyx::Activation::{Relu, Softmax};
use neuralnyx::CostFunction::CrossEntropy;
use neuralnyx::Optimizer::Adam;

fn main() -> std::io::Result<()> {
    // read the json file 
    let dataset = File::open("./dataset.json")?;
    let reader = BufReader::new(dataset);   // with a buffer
    let data: serde_json::Value = serde_json::from_reader(reader)?;
    
    // reorder the json to a collection of vectors
    let mut boards: Vec<Vec<f32>> = Vec::new();
    let mut moves: Vec<Vec<f32>> = Vec::new();

    for (board, optimal_move) in data.as_object().unwrap() {
        boards.push(board.chars().map(          // a move was encoded as a string so,
            |c| c.to_digit(10).unwrap() as f32  // change that to chars and then convert
        ).collect::<Vec<f32>>());               // them to a Vec<f32>

        let mut output_vec = vec![0.0f32; 9]; // one hot encode the outputs
        output_vec[optimal_move.as_u64().unwrap() as usize] = 1.0;
        moves.push(output_vec);
    }
    
    // create the neural network with our dataset
    let mut nn = NeuralNet::new(&mut boards, &mut moves, Structure {
        layers: vec![
            Layer {
                neurons: 12,
                activation: Relu,
            }, Layer {
                neurons: 9,
                activation: Softmax,    // probability distribution
            },
        ],
        cost_function: CrossEntropy,
        ..Default::default()
    }).unwrap();

    // you can js uncomment this if u get bored :P
    // nn.weights = vec![vec![vec![1.5330735, -0.41022286, -0.93067163, -0.7728315, -0.074884914, 3.999633, 0.8146035, 1.5549678, -1.2767547], vec![1.0763663, 1.0774628, 0.74208826, 1.4610659, -0.6994351, 0.3288528, -2.6427972, -1.478643, -0.18139262], vec![-1.8655983, -0.709942, 0.25405914, -0.68907005, 0.8540407, 1.3603798, 0.2667936, 1.2099667, -1.7083108], vec![0.5800438, -2.113427, 0.4707072, -0.82497764, 1.95639, 0.1885557, -0.22378999, 1.3732489, 0.657634], vec![1.8451821, -0.6080241, -1.7662125, -1.1323658, -3.6323462, 0.5323879, -1.2364094, -0.8544326, 1.3781376], vec![0.9811998, 0.6633981, -1.2674112, 0.13402134, -3.172574, -0.5315191, -0.054670185, 0.5798695, 1.170882], vec![-2.0013123, 0.71324503, -1.8413515, 1.6377034, -1.846366, -0.33830142, -2.5057833, 1.007805, 0.5541904], vec![0.668256, 5.3175416, 4.7329903, -0.62367034, 0.27885404, -2.0170789, -0.14243634, 0.29575124, 0.60629654], vec![2.571283, 0.09390665, -0.17706072, 0.04688488, -2.615452, 0.09744539, -0.930595, 0.31682068, 0.17487095], vec![-0.74130714, -0.60065085, -0.38920936, -0.35336587, -0.1254269, -0.453805, 0.5519366, -0.23374534, -0.09824553], vec![-0.3049535, 0.6423846, 0.45746017, 0.8915725, 0.22959524, 3.1681688, -0.1758806, -1.1422939, -1.0952953], vec![0.07275183, 0.31872746, -0.3966808, 0.3085187, -2.9967155, 0.6092052, 1.1557862, 1.5107332, 1.2167252], vec![0.249589, 1.2502855, 6.772055, 0.33740515, -0.24825308, -1.0614625, -0.8151544, -0.18630388, -1.3926835], vec![2.1547997, -3.4972537, -0.37281844, -2.0822077, 2.0897658, 0.010388439, 0.94455624, -0.20792437, 2.3720403], vec![0.07169564, 0.250852, -0.18265295, 1.8901128, -3.1377635, 0.30518618, 1.1722796, 1.9045535, 0.9024827]], vec![vec![1.6896774, 1.1329875, 2.298151, -1.7199419, -2.9129238, 2.2030733, -13.672678, 0.1814459, -4.734619, -1.0152781, -2.046505, -2.4677825, 0.3195156, 0.09949008, 1.4368851], vec![-1.5457675, -0.22771113, -2.1034667, -4.536146, -87.01669, -0.4345788, -22.049541, 0.7095113, 1.6376914, -0.4031465, 2.6456857, -2.7335389, -0.49609086, 
    // 2.595014, 0.37194857], vec![-1.0562694, 1.5429492, -60.443916, 4.3498836, 4.042594, -3.2920995, 7.713639, 1.0518239, 4.2728224, -0.21461117, 1.2459078, -1.5202192, -1.331024, -2.036318, -0.9122279], vec![-0.57249063, 0.40945667, -1.6525224, -0.9045069, -57.844074, -0.39407286, -123.14007, 0.35447907, -1.8719435, -0.3663277, -3.8181295, 
    // -2.8190932, -0.2908056, -0.13570625, 2.8203034], vec![0.89993787, -0.68374586, -70.06879, -7.6684504, 4.7464995, 4.7632904, -13.206044, -2.3831472, -3.277585, -0.2149436, -1.0721046, 1.6715078, 3.3158064, -2.9331071, -0.42913043], vec![0.6142998, -0.2999555, 0.5476399, -0.65785944, -63.261856, -1.0120302, -55.69476, 0.2419335, -0.35014138, -0.22894678, -0.9201115, 7.297105, 0.123604484, -0.2389575, -6.6276436], vec![1.0025848, 1.71533, -2.244226, -1.199488, 0.39650613, -0.13189891, -5.5637646, 0.71782005, -1.3440073, -0.18954556, -1.9969858, -1.7862836, -2.7865922, -0.41955268, 1.0201296], vec![-1.6561904, -1.4796913, 1.2427492, 1.9470676, -39.45143, -2.2517447, 3.5709374, -8.02955, 2.433286, -0.2265315, -2.043732, -0.36597356, 5.740214, 3.2149675, 2.1073792], vec![-4.2460155, -6.0340824, -0.56851196, 1.8382893, 35.532475, -7.4056163, 7.6265874, -0.23935917, -88.32142, 0.17763856, 3.879559, 6.4254727, -0.3240849, -2.701471, -2.151389]]];
    // nn.biases = vec![vec![-0.07876125, 0.6937629, -2.9777844, -4.260471, 0.16166444, 9.901743, 7.5773005, 0.9797591, 0.423399, -0.1081422, -4.509315, 9.491714, 2.8255558, -0.15325946, 9.617276], vec![-9.172163, -10.888536, -21.461878, 20.851992, -8.693955, 8.6321335, 19.654602, -5.2428784, 56.296734]];

    // train the neuralnet
    nn.train(TrainingOptions { // should reach about 0.2~
        optimizer: Adam(0.001),
        epochs: 20000,
        verbose: true,
        ..Default::default()
    });

    println!("{}", nn); // just print the weights and biases of the neural network to stdout

    Ok(())
}